
1) Aprendizado Semi-Supervisionado
    Link ref: 
        https://lamfo-unb.github.io/2017/05/09/Aprendizado-Semi-Supervisionado-para-Deteccao-de-Fraudes-Parte-1/
        https://lamfo-unb.github.io/2017/05/11/Aprendizado-Semi-Supervisionado-para-Deteccao-de-Fraudes-Parte-2/
        https://medium.com/@edmauryaishu/factor-analysis-researching-hidden-variables-pca-798783def458
        https://lamfo-unb.github.io/2017/05/12/Aprendizado-Semi-Supervisionado-para-Deteccao-de-Fraudes-Parte-3/
    Fichamento:
        Principal Component Analysis(PCA) is a great to reduce dimensionality and get rid of high correlation among independent variables. However, PCA abstracts away original meaning of variables and makes it harder to attach business logic to the variables being analysed.
        anomalias podem ser o resultado de atividade maliciosa, nesse caso, o advers√°rio est√° sempre tentado se adaptar para fazer com que as observa√ß√µes an√¥malas pare√ßam noramis.
        Aprendizado de m√°quina √© uma ci√™ncia que utiliza m√©todos da ci√™ncia da computa√ß√£o e estat√≠stica para analisar dados.
        As t√©cnicas de aprendizado de m√°quina surgiram dentro do campo de intelig√™ncia artificial, como um meio de permitir que os computadores aprendessem uma forma de conhecimento pr√≥pria.
        Dentro dos regimes de aprendizado de m√°quina, destaca-se o de aprendizado de m√°quina supervisionado, que foca em problemas de previs√£o: tendo uma base de dados com ‚Äúalvos‚Äù para cada observa√ß√£o (pares (x,y)), a meta √© aprender quais ‚Äúalvos‚Äù (y) est√£o associados a quais dados (x).
        Alguns exemplos desse tipo de problema s√£o: identificar a presen√ßa de uma doen√ßa (alvo), dado os sintomas do paciente (dados); prever se o pre√ßo da a√ß√£o de uma empresa vai subir ou cair (alvo), dado o hist√≥rico do mercado financeiro (dados); identificar de que pessoa √© a face (alvo) em uma imagem (dados) ou classificar um livro (dados) em uma escola liter√°ria (alvo).        
        Em cen√°rios de detec√ß√£o de anomalias, muitas vezes n√≥s s√≥ temos dados que representam o caso normal, sendo extremamente dif√≠cil conseguir dados que representam anomalias.
        Uma possibilidade √© utilizar aprendizado de m√°quina semi-supervisionado, em que consideramos apenas uma pequena parcela dos dados como estando nomeada e que os dados n√£o nomeados s√≥ cont√™m exemplos do caso normal, que geralmente √© abundante.
        Assim, n√≥s utilizamos t√©cnicas de aprendizado n√£o supervisionado (para aprender a estrutura dos dados) nos dados n√£o nomeados para extrair alguma no√ß√£o de normalidade.
        Ao final dessa etapa n√£o supervisionada, a m√°quina conseguir√° associar cada observa√ß√£o com uma pontua√ß√£o proporcional √† probabilidade do dado ter vindo da regi√£o normal. 
        Em problemas de previs√£o, a m√©trica de avalia√ß√£o mais comum √© a acur√°cia, que mede a propor√ß√£o de acertos.
        No entanto, nesse cen√°rio, como mais de 99% dos dados pertencem a uma √∫nica categoria, um preditor ing√™nuo prevendo todas as observa√ß√µes como sendo normais j√° conseguiria mais de 99% de acerto.
        Isso nos motiva a utilizar outras m√©tricas: precis√£o e revoca√ß√£o.
        Assim, um sistema ideal teria que ponderar precis√£o e revoca√ß√£o em algum ponto √≥timo.
        F2-score, que combina revoca√ß√£o e precis√£o, dando mais import√¢ncia a primeira.

        T√©cnicas de Detec√ß√£o de Anomalias 
            Modelo Gaussiano
                Intuitivamente, se um fen√¥meno tem comportamento gaussiano, podemos dizer que 95% das realiza√ß√µes desse fen√¥meno aconteceram a no m√°ximo 2 desvios padr√µes de dist√¢ncia da m√©dia.
                Por exemplo, se a quantidade m√©dia transacionada por cart√£o de cr√©dito for de R$ 50,00, com um desvio padr√£o de R$ 10,00, podemos dizer que 95% das transa√ß√µes ser√£o de um valor entre 30 e 70 reais.
                Quando encontramos a gaussiana multidimensional que melhor se encaixa nos dados, n√≥s podemos extrair a probabilidade de cada observa√ß√£o, que seria a altura da gaussiana multidimensional.
            Modelo Histograma
                Nem todas as vari√°veis dos nossos dados seguem uma distribui√ß√£o gaussiana.
                A come√ßar pela distribui√ß√£o da vari√°vel que mede a quantidade transacionada, que tem uma distribui√ß√£o bastante complicada, tanto para os dados normais quanto para os anormais. 
                vscode://file/D:/IFB/ptcc/image/hist1.png
                vscode://file/D:/IFB/ptcc/image/hist3.png
                Quando vemos esses histogramas, notamos facilmente como algumas vari√°veis s√£o √≥timos indicadores de anomalias, uma vez que a distribui√ß√£o (aproximada pelo histograma) dos dados an√¥malos e dos dados normais s√£o bastante distingu√≠veis. Veja por exemplo a vari√°vel V10.
            Modelo de Mistura de Gaussianas
                Como vimos nos histogramas acima, nem todas as vari√°veis seguem um modelo gaussiano. N√≥s podemos utilizar um modelo que relaxa essa hip√≥tese, assumindo que os dados v√™m de uma distribui√ß√£o que √© uma mistura de gaussianas.
                De fato, contanto que tenhamos gaussianas suficiente, qualquer distribui√ß√£o poder√° ser aproximada por uma mistura de gaussiana.
            Modelo de M√°quina de Suporte Vetorial
                M√°quinas de Suporte Vetoriais (MSV) s√£o uma classe de modelos originalmente desenhadas para problemas supervisionados de categoriza√ß√£o (ou classifica√ß√£o), em que o objetivo √© separar dois tipos de observa√ß√£o.
                Intuitivamente, o que os MSVs fazem √© achar o melhor plano de separa√ß√£o entre os dois tipos de dados.
                Para superar essa limita√ß√£o, as MSV fazer uso do truque do kernel, que representa os dados originais em um espa√ßo dimensional maior, de forma que seja poss√≠vel separar os dois tipos nesse novo espa√ßo.
                vscode://file/D:/IFB/ptcc/image/kerneltrick.png
                Na vers√£o n√£o supervisionada da MSV, n√£o estamos interessados em separar dois tipos de dados, pois os dados sequer s√£o nomeados com os tipos. Em vez disso, queremos achar a melhor esfera que encapsule todos os dados. 
                vscode://file/D:/IFB/ptcc/image/oneclasssvm.png
                Na verdade, n√≥s podemos dizer que o modelo n√£o supervisionado de MSV √© um aproximador universal de fun√ß√µes densidade de probabilidade, isto √©, ele √© capaz de aproximar qualquer distribui√ß√£o poss√≠vel.
                Uma severa desvantagem desse m√©todo √© o fato dele ser extremamente ineficiente para treinar. 
            Modelo de Floresta de Isola√ß√£o
                O modelo de floresta de isola√ß√£o √© outro modelo que podemos considerar como um aproximador universal de distribui√ß√µes.
                O modelo de floresta de isola√ß√£o ajusta v√°rias √°rvores de isola√ß√£o aos dados.
                Para construir cada √°rvore de isola√ß√£o, primeiro selecionamos aleatoriamente uma das vari√°veis nos dados.
                Em seguida, selecionamos um valor aleat√≥rio entre o m√°ximo e o m√≠nimo dessa vari√°vel, que ser√° utilizado para separar os dados.
                N√≥s continuamos fazendo essas segmenta√ß√µes aleat√≥rias at√© que todas as observa√ß√µes estejam isoladas, isto √©, separadas das demais. 
                Nossa esperan√ßa √© que as anomalias sejam distintas dos dados normais, sendo que esses se aglomeram em algum local do espa√ßo, enquanto que aquelas ficam mais isoladas.                
                Cabe ainda ressaltar que vantagens dessa metodologia frente √†s m√°quinas de suporte vetorial s√£o a velocidade de treinamento e a capacidade de f√°cil paraleliza√ß√£o.
            Modelo Neural
                Nos √∫ltimos anos, redes neurais se tornaram o canivete su√≠√ßo de aprendizado de m√°quina, tanto pela sua flexibilidade e efetividade na maioria dos cen√°rios que envolvem problemas estat√≠sticos de alta complexidade e n√£o linearidade. 
                Para impedir que a rede neural simplesmente copie o que lhe foi passado como reconstru√ß√£o perfeita, n√≥s colocamos uma camada de neur√¥nios estreita no meio da rede neural.
                Essa cama ter√° apenas dois neur√¥nios e como os nossos dados t√™m 30 vari√°veis, isso significa que a rede neural ter√° que aprender uma representa√ß√£o interna que condense 30 dimens√µes em apenas duas.
        
        M√©todos semi-supervisionados de aprendizado de m√°quina s√£o excelentes em cen√°rios de detec√ß√£o de anomalias, em que h√° pouqu√≠ssimos exemplos do caso an√¥malo. 



    Anota√ß√µes pessoais.
        alvo √© situa√ß√£o almejada que a m√°quina identifique.
        alvo positivo √© a situa√ß√£o desejada.
        alvo negativo √© a situa√ß√£o n√£o desejada?
        t√©cnica PCA permite manter a informa√ß√£o integral dos dados ao mesmo tempo que retira sua interpretabilidade. 
        existe um tradeoff entre precis√£o e revoca√ß√£o.
        revoca√ß√£o = recall = revocabilidade = o qu√£o completos os resultados est√£o = medida de completude ou quantidade
        precis√£o = o quanto os resultados da pesquisa s√£o √∫teis = medida de exatid√£o ou qualidade
        
2) PMML - PREDICTIVE MODEL MARKUP LANGUAGE
    LINK REF:
        https://repositorio.unb.br/bitstream/10482/16954/1/2014_JoseAbiliodePaivaRamos.pdf
        https://www.ibm.com/developerworks/library/ba-ind-PMML1/index.html
    Fichamento:
        Uma vez que o sucesso de uma hip√≥tese ou modelo induzido por um algoritmo de AMdepende dos dados dispon√≠veis [40], s√£o utilizadas t√©cnicas para a melhoria da qualidadedos mesmos.
        PREPARA√á√ÉO DOS DADOS
            ELIMINA√á√ÉO MANUAL DE ATRIBUTOS
                Outros atributos que n√£o agregaminforma√ß√£o √∫til s√£o n√∫meros sequenciais de controle, como identificadores de registro.
            INTEGRA√á√ÉO DE DADOS
            AMOSTRAGEM DE DADOS
                Algoritmos de AM podem ter dificuldades no trato de amostra de dados com muitosobjetos, em virtude das respectivas complexidades computacionais.  
                Para resolver esteproblema, usa-se um subconjunto dos dados.
            BALANCEAMENTO DE DADOS
                Em v√°rios conjuntos de dados reais, o n√∫mero de objetos varia para as diferentes classese isto pode constituir um problema para v√°rios algoritmos de AM, pois estes algoritmospodem ter dificuldades para aprender o conceito relacionado √† classe minorit√°ria.
                Quando alimentados com dados desbalanceados, esses algoritmos tendem a gerar ummodelo que favorece a classifica√ß√£o de novos dados na classe majorit√°ria
            LIMPEZA DE DADOS
                Os dados com ru√≠dos podem levar a um superajuste do modelo, pois o algoritmoque induz o modelo pode se ater √†s especificidades relacionadas aos ru√≠dos, em vez dadistribui√ß√£o verdadeira que gerou os dados; por outro lado, a elimina√ß√£o desses dadospode fazer com que algumas regi√µes do espa√ßo de atributos n√£o sejam consideradas noprocesso de indu√ß√£o de hip√≥teses.
            REDU√á√ÉO DA DIMENSIONALIDADE
                Para que objetos com um n√∫mero elevado de atributos possam ser utilizados em mui-tos algoritmos de AM, a quantidade de atributos precisa ser reduzida.
                As t√©cnicas de redu√ß√£o de dimensionalidadepodem ser divididas em duas grandes abordagens: agrega√ß√£o e sele√ß√£o de atributos.
                Enquanto as t√©cnicas de agrega√ß√£o substituem parte dos atributos originais por novos atributos formados pela combina√ß√£o de grupos de atributos, as t√©cnicas de sele√ß√£o mant√™muma parte dos atributos originais e desconsideram os demais.
                A An√°lise de Componentes Principais ou Principal Component Analysis (PCA)√© um exemplo de t√©cnica de agrega√ß√£o.
                    Este m√©todo busca combina√ß√µes lineares, chamada sde componentes principais, que capturam, de maneira resumida, a maior variabilidade poss√≠vel dos dados.
                    A principal vantagem da PCA como m√©todo de redu√ß√£o de dimensionalidade encontrase na constru√ß√£o de componentes n√£o-correlacionados.
                    O uso de atributos correlacionadosem alguns algoritmos de AM, como regress√£o log√≠stica ou redes neurais, pode introduzir erro e diminuir o desempenho do algoritmo.
                    Uma vez que n√£o h√° relacionamento entre os atributos e os r√≥tulos dos objetos, os componentes principais n√£o prov√™em um relacionamento apropriado com as categorias dos objetos em tarefas de aprendizado supervisionado.
                Testeœá2
                    Por sua vez, as t√©cnicas de sele√ß√£o avaliam a relev√¢ncia do atributo antes da aplica√ß√£ode algum modelo de AM. 
                    Somente os atributos correlacionados com os r√≥tulos dos objetos ser√£o considerados na aplica√ß√£o do modelo.
                    O grau de associa√ß√£o entre duas vari√°veis analisadas pelo testeœá2pode ser representado pelocoeficiente de conting√™ncia de Pearson (CC).
                    O coeficiente de conting√™ncia √© nulo quando n√£o h√° associa√ß√£o entre as vari√°veis equanto maior o valor de CC, maior ser√° a associa√ß√£o entre as vari√°veis.
            TRANSFORMA√á√ÉO DE DADOS
                As t√©cnicas de transforma√ß√£o de dados podem ser utilizadas para converter valores simb√≥licos em valores num√©ricos, ou vice-versa.
                [POIS] Alguns algoritmos de AM est√£o limitados √† manipula√ß√£o de valores de determinados tipos, por exemplo, apenas valores num√©ricos (t√©cnicas como redes neurais e m√°quinas de vetores de suporte) ou apenas valores simb√≥licos (√°rvores de decis√£o ID3, por exemplo).
                Convers√£o Simb√≥lico-Num√©rico
                    Para um atributo simb√≥lico com mais de dois valores, a t√©cnica utilizada na convers√£o depende de o atributo ser nominal ou ordinal.
                    Se n√£o houver rela√ß√£o de ordem entre os atributos simb√≥licos, esta propriedade deve ser mantida para os valores num√©ricos gerados.
                    dist√¢ncia de Hamming: a dist√¢ncia entre duas sequ√™ncias bin√°rias com mesmo n√∫merode elementos √© igual ao n√∫mero de posi√ß√µes em que as sequ√™ncias apresentam valores diferentes.
                    Se existe uma rela√ß√£o de ordem entre os valores nominais, a codifica√ß√£o deve manter essa propriedade:  basta ordenar os valores categ√≥ricos ordinais e codificar cada valor de acordo com sua posi√ß√£o na ordem, utilizando-se n√∫meros inteiros ou reais.
                Convers√£o Num√©rico-Simb√≥lico
                    Se o atributo original for formado por sequ√™ncias bin√°rias sem uma rela√ß√£o de ordem entre si, cada sequ√™ncia pode ser substitu√≠da por um nome ou categoria.
                Transforma√ß√£o de Atributos Num√©ricos
                    Algumas vezes, o valor num√©rico de um atributo precisa ser transformado em outro valor num√©rico; 
                    Uma transforma√ß√£o que √© muito utilizada √© a normaliza√ß√£o de dados: a cada valor do atributo a ser normalizado √© adicionada (ou subtra√≠da) uma medida de localiza√ß√£o e o valor resultante √© em seguida multiplicado (ou dividido) por uma medida de escala.
        MODELOS PREDITIVOS
            Um algoritmo de AM preditivo produz, dado um conjunto de objetos rotulados, um modelo capaz de produzir previs√µes a respeito dos objeto.
            Os r√≥tulos dos objetos assumem valores em um dom√≠nio conhecido.
            Se o dom√≠nio for um conjunto infinito e ordenado de valores, tem-se um problema de regress√£o e o modelo gerado √© um regressor; por outro lado, se esse dom√≠nio for um conjunto de valores nominais, tem-se um problema de classifica√ß√£o e o modelo gerado √© um classificador.
            Os classificadores podem ser gerados por diversos algoritmos de AM preditivos, por exemplo: k-NN, naive Bayes, m√°quinas de vetores de suporte, redes neurais artificiais (RNA), √°rvores de decis√£o. 
            Por ader√™ncia ao problema deste trabalho, foramescolhidas √°rvores de decis√£o para a identifica√ß√£o de transa√ß√µes fraudulentas.
        TRABALHOS CORRELATOS
            A maioria dos trabalhos publicados sobre detec√ß√£o de fraudes est√° relacionada ao do-m√≠nio de cart√£o de cr√©dito, concess√£o de cr√©dito, intrus√£o de computadores e fraudes em servi√ßos de telecomunica√ß√µes.
            Kovach prop√µe uma arquitetura de um sistema de detec√ß√£o de fraudes banc√°rias, realizadas atrav√©s daInternet, em tempo real baseada na teoria matem√°tica de evid√™ncias de Dempster-Shafer. [NAO √â POSS√çVEL COMPARAR COM A ATUAL ESTUDO]
        √ÅRVORES DE DECIS√ÉO
            Uma √°rvore de decis√£o usa a estrat√©gia dividir para conquistar na solu√ß√£o de um problema de decis√£o: um problema complexo √© dividido em problemas mais simples, aos quais recursivamente √© aplicada a mesma estrat√©gia; as solu√ß√µes dos subproblemas podem ser combinadas, na forma de uma √°rvore, para gerar uma solu√ß√£o do problema complexo.
            Formalmente, uma √°rvore de decis√£o √© um grafo ac√≠clico direcionado em que cada n√≥ ou √© um n√≥ de divis√£o, com dois ou mais sucessores, ou um n√≥ folha.
            INDU√á√ÉO DE √ÅRVORES DE DECIS√ÉO
                O processo de constru√ß√£o de uma √°rvore a partir de uma amostra de treinamento √© conhecido como indu√ß√£o da √°rvore.
            [...]                
        MEDIDAS DE DESEMPENHO
        PMML
            utilizado para representar modelos de minera√ß√£o de dados e permite a representa√ß√£o de diversos modelos como √°rvores de decis√£o, redes neurais ou classificador naive Bayes.
            A estrutura geral de um documento PMML √© composta por um cabe√ßalho, dicion√°rio de dados, transforma√ß√µes de dados e modelo.
        MATERIAL E M√âTODO
            Cada objeto nesta base de dados possuem dois atributos com fun√ß√£o de r√≥tulo: um atributo para identificar as transa√ß√µes que foram apontadas como fraudulentas pelas regras ad-hoc elaboradas pelos especialistas da institui√ß√£o fornecedora dos dados e outro para indicar quais est√£o rotuladas como fraudulentas.
            METODO
                [NESTE] trabalho ser√° utilizada a metodologia de minera√ß√£o de dados CRISP-DM (CrossIndustry Standard Process for Data Mining) para condu√ß√£o do projeto de constru√ß√£o do classificador para identifica√ß√£o de transfer√™ncias banc√°rias fraudulentas, pois √© uma metodologia madura para guiar projetos de minera√ß√£o de dados.
                O ciclo de vida do projeto de minera√ß√£o, nesta metodologia, √© composto de seis fases: entendimento do neg√≥cio, entendimento dos dados, prepara√ß√£o dos dados, modelagem, avalia√ß√£o e implanta√ß√£o.
        EXPERIMENTOS
            ENTENDIMENTO DO NEG√ìCIO
                o custo financeiro de uma transa√ß√£o fraudulenta n√£o alertada, falso-negativo, √© superior ao custo de uma transa√ß√£o leg√≠tima apontada como fraudulenta, falso-positivo; pois quando uma transa√ß√£o leg√≠tima √© apontada como fraudulenta, o tratamento deste alerta envolve o custo da m√£o-de-obra necess√°ria para analis√°-lo.
                Por suavez, se a fraude n√£o for detectada, al√©m do preju√≠zo financeiro, a conta vitimada pode ser utilizada para recebimento de outros cr√©ditos fraudulentos.
                Neste contexto, a identifica√ß√£o de transa√ß√µes fraudulentas baseada em m√©todos ad-hoc,nos quais as regras de detec√ß√£o s√£o exclusivamente escritas por especialistas do dom√≠nio,n√£o √© aceit√°vel, pois, normalmente s√£o muito laboriosas e requerem muito tempo para elabora√ß√£o e implanta√ß√£o ficando desatualizadas rapidamente.
                Cada objeto nesta base de dados √© composto por 10 atributos de tipo num√©rico discreto, 7 atributos de tipo num√©rico cont√≠nuo e 5 atributos categ√≥ricos.
                Para minimizar o problema das classes extremamente desbalanceadas foram aplicadas duas regras definidas pelos especialistas do dom√≠nio que excluem transa√ß√µes que rara-mente s√£o fraudulentas, estas regras especialistas baseiam-se em perfis transacionais e naagrega√ß√£o de atributos para a extra√ß√£o de informa√ß√£o latente nos dados.
            PRPARA√á√ÉO DOS DADOS
                Estes atributos foram nomeados como v01,v02, ...,v041,v_regra,alvo; onde v_regra indica os alertas das regras ad-hoc e alvo corresponde ao r√≥tulo das transa√ß√µes.
                foi utilizado o teste œá2 para estimar o grau de associa√ß√£o entre os atributos nominais/num√©ricos discretos e o r√≥tulo fraude o un√£o-fraude, representado pela vari√°vel alvo.
                Com rela√ß√£o √† representatividade das amostras, geralmente n√£o √© poss√≠vel afirmar se uma amostra √© representativa ou n√£o, para mitigar este problema √© utilizado o processo de estratifica√ß√£o: cada classe no conjunto de dados original deve ser representada na mesma propor√ß√£o nas amostras de teste, valida√ß√£o e treinamento.
            MODELAGEM
                Para indu√ß√£o do classificador utilizou-se o algoritmo C5.0 um sistema inicialmente comercial da Rule Quest Research e agora tamb√©m distribu√≠do sob a licen√ßa GNU GPL.
            ARVORES DE DECIS√ÉO
                O algoritmo 5.0 constr√≥i a √°rvore atrav√©s a divis√£o da amostra de treinamento com base no teste que resulta na maior raz√£o de ganho.
                Cada subconjunto obtido da primeira divis√£o √© novamente divido pela aplica√ß√£o de um novo teste e este processo √© repetido at√© que nenhuma outra divis√£o seja poss√≠vel.
                Por fim, a simplifica√ß√£o da √°rvore com a poda dos n√≥s que n√£o contribuem para a tarefa de classifica√ß√£o √© realizada atrav√©s da poda pessimista embutida no C5.0.
                BALANCEAMENTO
                    Muitos algoritmos de classifica√ß√£o t√™m sua acur√°cia prejudicada quando as classes possuem quantidades de objetos muito diferentes.
                    Nesta situa√ß√£o a classe majorit√°ria pode ser reduzida, a classe minorit√°ria pode ser inflada ou uma combina√ß√£o de ambas as t√©cnicas.
                PODA
                    A extens√£o da poda da √°rvore √© determinada pelo par√¢metro n√≠vel de confian√ßa que possui valor padr√£o de 25%.
                    A diminui√ß√£o deste valor resulta em √°rvores menores e mais concisas, privilegiando a capacidade de generaliza√ß√£o do modelo; por outro lado, o aumento do n√≠vel de confian√ßa √© usado para a obten√ß√£o de √°rvores de maior acur√°cia, devido ao maior ajustamento aos dados de treinamento.
                CRITERIO DA PARADA
                    A √°rvore gerada pelo algoritmo C5.0 cresce at√© que todos os objetos em um n√≥ folha perten√ßam √† mesma classe ou o n√∫mero de objetos nos n√≥s resultantes da aplica√ß√£o de um dado teste condicional n√£o sejam inferiores a um dado limiar.
                APLICA√á√ÉO DE CUSTOS
                    O algoritmo C5.0 permite a utiliza√ß√£o de custos, quando da ocorr√™ncia de classifica√ß√µes incorretas, visando ao aumento da acur√°cia da √°rvore de decis√£o gerada.
            REDES NEURAIS ARTIFICIAIS
                Para compara√ß√£o com o modelo gerado atrav√©s do algoritmo C5.0, foram constru√≠das redes neurais artificais perceptron multicamadas, pois este tipo de rede permite a representa√ß√£o de relacionamentos complexos entre os dados.
            IMPLANTA√á√ÉO
                Nesta etapa foi realizada a incorpora√ß√£o do classificador obtido, a √°rvore de decis√£o, no processo de neg√≥cio.
                A √°rvore de decis√£o no formato PMML foi interpretada por uma aplica√ß√£o constru√≠da com base na API Java JPMML-Evaluator, Java Evaluator API for Predictive Model Markup Language (PMML), ap√≥s a inclus√£o de classes para comunica√ß√£o com os bancos de dados utilizados.
                A atualiza√ß√£o √© realizada sob demanda quando do surgimento de uma nova modalidade de ataque ou quando observa-se redu√ß√£o nas m√©tricas precis√£o e sensibilidade.
                A cada atualiza√ß√£o √© gerada uma nova √°rvore de decis√£o que √© exportada no formato PMML para utiliza√ß√£o na camada de avalia√ß√£o de transa√ß√µes.
                A integra√ß√£o destas duas camadas permitiu imprimir celeridade na atualiza√ß√£o dos modelos de identifica√ß√£o de fraudes, pois cada nova √°rvore √© gerada, em m√©dia, em 15 minutos.
                
3) 
    LINK REF: http://bibliotecadigital.fgv.br/dspace/bitstream/handle/10438/27166/Dissertacao_Joao_Carlos_Pacheco_VFinal_2.pdf?sequence=3&isAllowed=y
    FICHAMENTO:
        O ojetivo do trabalho √© identificar transa√ß√µes de cr√©dito fraudulentas ap√≥s a primeira aprova√ß√£o de cr√©dito.
        REVISAO TEORICA - T√©cnicas de amostragem de dados e medidas de avali√ß√£o dos modelos preditivos:
            regress√£o log√≠stica
                funcao resposta
                estima√ß√£o dos par√¢metros
            aprendizado de m√°quina  
                aprendizado supervisionado
                    No  aprendizado  supervisionado  como  apresentado  por  Barber  (2012)  existe uma base de dados pr√©vios com as caracter√≠sticas dos dados que denotaremos por ùë• e  sua  classifica√ß√£o  que  denotaremos  por ùë¶.
                    Neste  processo  √©  criada  uma  base de treinamento, com uma amostra dos dados, onde o algoritmo ir√° identificar quais caracter√≠sticas presentes em ùë• s√£o suficientes para chegar √† classifica√ß√£o de ùë¶.
                aprendizado n√£o supervisionado
                    No aprendizado n√£o-supervisionado n√£o existe uma base de dados pr√©via que permite que os modelos sejam desenvolvidos com uma base de treinamento, portanto o  modelo  dever√°  ser  executado  conforme  as  informa√ß√µes  s√£o  geradas.
                    Esta  abordagem visa identificar padr√µes em bases de dados, mas sem a exist√™ncia de uma resposta pr√©via para a classifica√ß√£o que ser√° identificada.
                aprendizado semi-supervisionado
                    No aprendizado de m√°quina, √© comum possuir uma pequena quantidade de dados rotulados frente a uma grande quantidade de dados n√£o rotulados.
                    No aprendizado semi-supervisionado, utiliza-se os dados n√£o rotulados para tentar  criar  um  classificador  melhor  do  que  o  criado  com  base  apenas  nos  dados rotulados.
                maquina de vetores de suporte
                    possui grande capacidade na detec√ß√£o de padr√µes, sendo assim capazes de identificar opera√ß√µes fraudulentas de cart√µes de cr√©ditos, identificar d√≠gitos escritos a m√£o, al√©m de serem utilizados coms ucesso em v√°rias aplica√ß√µes biol√≥gicas
                rede bayesianas
                    Ao analisarmos um problema, muitas vezes podemos acreditar que um evento afeta outro e existem eventos que s√£o independentes. 
                    para que este tipo de informa√ß√£o seja utilizado de forma eficiente utilizamos estruturas de grafos que nos permitem descrever como os objetos s√£o vinculados e fornecem uma imagem conveniente da rela√ß√£o dos objetos (eventos).
                metodos de emsemble
                    Os m√©todos Ensemble possuem como principal objetivo combinar o poder preditivo de v√°rios estimadores por meio de um algoritmo de aprendizado, visando aperfei√ßoar a generaliza√ß√£o e robustez quando comparado a um estimador utilizado sozinho.
                bootstrap aggregating - baggind
                    Este procedimento possui a caracter√≠stica de melhorar o desempenho de pre-ditores inst√°veis que s√£o basicamente os preditores com alta vari√¢ncia
                boosting
                    o m√©todo deBoostingse refere a fam√≠lia de algoritmos que consegue converter preditores fracos em fortes preditores.
                bases de dados desbalanceadas
                    Uma das caracter√≠sticas marcantes das bases de dados que possuem infor-ma√ß√µes de fraude √© o desbalanceamento.
                    os  principais  m√©todos  utilizados  para  modelagem  em  base  de  dados desbalanceadas, sendo que neste trabalho foi utilizada a t√©cnica deRandom Under-sampling.
                    O  procedimento  de oversampling aleat√≥rio  tem  como  mecanismo  criar  uma amostra da classe minorit√°ria maior que a dispon√≠vel, ou seja, √© criado um conjuntode exemplos selecionados de forma aleat√≥ria da classe minorit√°ria ùëÜùëöùëñùëõ, que s√£o inseridos na amostra ùê∏, posteriormente esta subamostragem √© inserida na base de testesoriginal ùëÜ.
                selecao de variaveis
                    Portanto foi selecionado para os modelos lineares a t√©cnica de Stepwise, j√° para os modelos que utilizam m√©todos de aprendizado de m√°quina utilizamos o procedimento de sele√ß√£o sequencial usando o modelo de Random Forest.
                m√©tricas de avalia√ß√£o de desempenho do modelo   
                    A representa√ß√£o da performance da classifica√ß√£o tamb√©m pode ser formulada por meio da matriz de confus√£o que descreve os custos de se fazer atribui√ß√£o das classes √†s amostras, portanto cada uma das linhas da matriz cont√©m cada classe pass√≠vel de ser atribu√≠da √†s inst√¢ncias pelo classificador, enquanto cada coluna possui a classe √† qual as amostras efetivamente pertencem na realidade.
                    A m√©trica de Precision fornece a informa√ß√£o de precis√£o. 
                        Portanto podemos dizer que est√° m√©trica √© intuitivamente a capacidade do classificador n√£o rotular como positiva uma amostra que √© negativa.
                    A m√©trica de Recall fornece informa√ß√£o de recorda√ß√£o.
                        Portanto podemos dizer que est√° m√©trica √© intuitivamente a capacidade do classificado encontrar todas as amostras positivas.
                    m√©trica de F-Mensure, que tamb√©m √© conhecida como F-score ou F1 score,√© a combina√ß√£o das m√©tricas anteriores de recorda√ß√£o e precis√£o e pode ser interpretada como uma m√©dia ponderada destas m√©tricas, assim a m√©trica F-Mersure alcan√ßao seu melhor valor em 1 e o pior em 0.
                    receiver operating characterisctics (ROC) curves
                    teste kolmogorov-smirnov
        METODOLOGIA
            etapas: pre processamento, constru√ß√£o de amostras, sele√ß√£o das variaveis e aplicacao dos modelos
            utilizou python para todos exceto na avalia√ß√£o de desempenho que utilizou o R
            A base de treinamento foi a utilizada para treinar o classificador, visando construir um modelo, por sua vez a base de teste √© utilizada para identificar o poder de generaliza√ß√£o do modelo, sendo que esta base n√£o foi utilizada no desenvolvimento do modelo.
            foi realizada uma amostragem da base de treinamento, visando deixar o √≠ndice de desbalanceamento baixo, tornando a propor√ß√£o de casos positivos iguais aos casos negativos.
            utilizamos o procedimento de undersample que seleciona todos os casos  positivos,  logo  em  seguida  seleciona  de  forma  rand√¥mica  na  base  de  teste a mesma quantidade de casos negativos, tornando assim a base balanceada.
            Assim aplicamos um m√©todo que identifica colinearidade acima de 98% entre as vari√°veis presentes na base de dados, de tal modo que dos pares de recursos com alta colinearidade apenas um √© selecionado para remo√ß√£o, sendo que apenas uma das vari√°veis precisa ser removida.
            O procedimento adotado necessitadas vari√°veis que iremos prever neste trabalho, buscando identificar quais vari√°veis possuem import√¢ncia zero utilizando o modelo de aprendizado Gradient Boosting.
            visa identifica a exist√™ncia de alguma vari√°vel que possua um valor √∫nico, pois este tipo de vari√°vel possui o comportamento semelhante ao de uma constante.
            nesta etapa foi realizada uma avalia√ß√£o que garanta que os modelos n√£o incorram no erro de utilizar poucas vari√°veis, gerando assim um underfitting
            Para os modelos lineares utilizamos a t√©cnica de Stepwise, para selecionar asvari√°veis para o modelo.
            foi utilizada a linguagem de programa√ß√£oPythoncom o projeto scikit-learn.
            NumPy,SciPy,Matplotlib e Pandas.
            O segundo passo do trabalho foi criar um modelo capaz de predizer todas as vari√°veis respostas ao mesmo tempo. De tal modo como t√©cnica selecionada neste trabalho, foi utilizado o algoritmo Randon Forest que possui suporte para classifica√ß√£o multi-output, ou seja, com m√∫ltiplas sa√≠das.
            Para realizar um contraponto no m√©todo de multi-output nativo do classificador Ensenble Randon Forest foi utilizado o procedimento implantado pelo projeto scikit-learn MultiOutputClassifier, que fornece um meio de utiliza√ß√£o de qualquer classificador para uma classifica√ß√£o de m√∫ltiplas vari√°veis respostas
            Ao avaliar todos os resultados a resposta n√£o pode ser direta pois existe um ‚Äúperde-e-ganha‚Äù  quando  avaliamos  todos  os  resultados  conjuntamente,  sendo  que cada uma das metodologias possui as suas vantagens e desvantagens.
            Nesta etapa do trabalho, ser√£o avaliadas as vari√°veis selecionadas pelo m√©todo de sele√ß√£o sequencial, com uso do classificador RF, para os modelos que utilizam t√©cnicas de aprendizado de m√°quina.
            A √∫nica vari√°vel que esteve presente no treinamento de todos os modelos, independente da vari√°vel resposta foi a que identifica a quantidade de respons√°veis pelos domic√≠lio particular.

4)
    LINK  REF: https://medium.com/ensina-ai/detectando-fraudes-financeiras-usando-aprendizado-de-m%C3%A1quina-ganhando-a-guerra-contra-dados-3280893d09cb
    FICHAMENTO:
        No Aprendizado de M√°quina, problemas como a detec√ß√£o de fraudes s√£o geralmente considerados problemas de classifica√ß√£o ‚Äî prever a classe correspondente a uma dada observa√ß√£o.
        o problema de classifica√ß√£o requer a cria√ß√£o de modelos com intelig√™ncia suficiente para classificar adequadamente as transa√ß√µes como sendo leg√≠tima ou fraudulenta, a partir de detalhes tais como valor, estabelecimento, localiza√ß√£o, data e hora, entre outros.
        O principal desafio que enfrentamos, ao modelar a detec√ß√£o de fraudes como um problema de classifica√ß√£o, reside no fato que a grande maioria das transa√ß√µes n√£o √© fraudulenta. 
        E uma das principais miss√µes de um Cientista de Dados √© criar valor para o neg√≥cio a partir dos dados.
        Esses dados correspondem a transa√ß√µes ocorridas em dois dias, onde observa-se 492 fraudes dentre 284.807 transa√ß√µes. 
        Esses dados s√£o altamente desbalanceados, sendo que a classe positiva (fraudes) representa apenas 0,172% de todas as transa√ß√µes.
        Sempre √© bom fazer uma EDA ‚Äî An√°lise Explorat√≥ria de Dados antes de come√ßar a trabalhar em modelos de previs√£o e an√°lise. 
        maneiras de tratar dados desbalanceados:
            oversampling (super amostragem) - smote (synthetic minotiry over-sampling techinique)
                realizar uma super-amostragem significa criar artificialmente novas observa√ß√µes em nosso conjunto de dados que perten√ßam √† classe que est√° sub-representada.
                realiza os seguintes passos:
                    1) busca por k-nearest-neighbors (observa√ß√µes similares) da classe minorit√°ria
                    2) coleta um dos k-nearest-neighbors e o utiliza para criar novas obser√ß√µes artificialmente.
                existem v√°rias implementa√ß√µes smote, tais como: imblearn
                REF: https://jair.org/index.php/jair/issue/view/1100
            undersampling (sub amostragem) - random under sampler
                Na sub-amostragem, √© a classe dominante que sofre amostragem, a fim de reduzir o seu n√∫mero de observa√ß√µes.
                Isso pode ser feito com a escolha aleat√≥ria de um conjunto reduzido de amostras.
                A classe RandomUnderSampler da biblioteca imblearn √© uma forma f√°cil e r√°pida de balancear os dados atrav√©s da sele√ß√£o aleat√≥ria de um subconjunto de dados das classes escolhidas.  
            m√©todos de classes combinadas - smote + enn
                A t√©cnica SMOTE pode acabar gerando novas amostras indesejadas quando, ao fazer a interpola√ß√£o entre dois pontos, um deles √© marginalmente outlier.
                utilizaremos a SMOTE em conjunto com o algoritmo de vizinhos-mais-pr√≥ximos editados (edited nearest-neighbours ‚Äî ENN, em ingl√™s).
                o ENN √© utilizado como m√©todo de ‚Äúlimpeza‚Äù do espa√ßo resultante ap√≥s a super-amostragem via SMOTE.
        Random Forest Classifier para fazer a previs√£o de transa√ß√µes fraudulentas.
        adicionar uma nova dimens√£o √† nossa an√°lise e conferir a √Årea Sob a Caracter√≠stica de Opera√ß√£o do Receptor (Area Under the Receiver-Operating Characteristic ‚Äî AUROC, em ingl√™s). 
        Intuitivamente, a AUROC indica o qu√£o prov√°vel √© que o seu modelo fa√ßa a distin√ß√£o entre as duas classes.
        Em outras palavras, se voc√™ selecionar aleatoriamente uma observa√ß√£o de cada classe, qual a probabilidade do seu modelo ser capaz de ‚Äúorden√°-las‚Äù corretamente?
        SMOTE
            √© importante analisar o impacto financeiro dessa mudan√ßa (diminui√ß√£o da precis√£o e aumento do recall ):
                preju√≠zo financeiro decorrente de um aumento de falsos negativos, correspondendo a um decr√©scimo da precis√£o na detec√ß√£o de fraudes.
                poder√≠amos perder clientes ao classificar suas transa√ß√µes erroneamente como fraudes, al√©m de resultar em maiores custos operacionais decorrentes do cancelamento, emiss√£o e envio de novos cart√µes para os clientes.
        RandomUnderSampler
            A sub-amostragem se mostrou uma p√©ssima abordagem para esse problema.
            melhora recall e piora precis√£o
        SMOTE + ENN
            A SMOTE + ENN mostrou-se a melhor abordagem em nosso exemplo.
            reduz precis√£o e aumenta recall

    
    5) REF: https://github.com/juniorcl/transaction-fraud-detection
    https://www.overleaf.com/